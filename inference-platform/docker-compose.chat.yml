version: "3.9"

services:
  # Chat - Qwen 2.5 7B on GPU 1
  chat:
    image: vllm/vllm-openai:latest
    container_name: vllm-chat
    restart: unless-stopped
    ipc: host
    environment:
      - HF_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=1
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ${HF_HOME:-./hf-cache}:/root/.cache/huggingface
    expose:
      - "8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
    command: >
      --model Qwen/Qwen2.5-7B-Instruct
      --host 0.0.0.0
      --port 8000
      --api-key ${BACKEND_API_KEY}
      --max-model-len 8192
      --gpu-memory-utilization 0.95
      --dtype auto
      --enable-auto-tool-choice
      --tool-call-parser hermes

networks:
  default:
    name: inference-network
    external: false
